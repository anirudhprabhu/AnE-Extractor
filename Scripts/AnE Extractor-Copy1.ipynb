{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action and Event Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract essential information from Raw text to create a Narrative in Situation Calculus\n",
    "\n",
    "We need to create a factbase from the information contained in the Raw text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process full text\n",
    "\n",
    "Need to process multiple large books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and store sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Process `text` with Spacy NLP Parser\n",
    "text = read_file('/Users/anirudhprabhu/PycharmProjects/novelWriter/Skeleton/docs/books_txt/Fantasy/465179.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_text = nlp(text)\n",
    "#print(processed_text)\n",
    "\n",
    "spacy.displacy.serve(processed_text,style = \"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in processed_text:\n",
    "    print(token.text_with_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sentences are in the book (Pride & Prejudice)?\n",
    "sentences = [s for s in processed_text.sents]\n",
    "print(len(sentences))\n",
    "\n",
    "# Print sentences from index 10 to index 15, to make sure that we have parsed the correct book\n",
    "print(sentences[50:55])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps taken for Extraction of Actions : \n",
    "\n",
    "### (Based on Han's Relation Extraction)\n",
    "\n",
    "* Run Dependency Parsing\n",
    "* Extract Root\n",
    "* If Root is a finite verb, then the Verb is the action word.\n",
    "* If Root is a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_index = []\n",
    "i = 1\n",
    "for token in processed_text.sents:\n",
    "    print(token)\n",
    "    i += 1\n",
    "    #if token.dep_ == 'ROOT' and token.head.pos_ == 'VERB' :\n",
    "    #    sent_index.append(i)\n",
    "#print(sent_index)\n",
    "\n",
    "#for q in sent_index:\n",
    "#    print(processed_text.sents[s])\n",
    "    \n",
    "sentences = [s for s in processed_text.sents]\n",
    "print(len(sentences))\n",
    "\n",
    "for index in sent_index:\n",
    "    print(sentences[sent_index[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'’s': 88, 'was': 85, 'asked': 78, 'is': 70, 'said': 58, 'looked': 54, 'turned': 46, 'thought': 44, 'have': 36, 'replied': 27, 'know': 26, 'stared': 26, 'be': 24, '’re': 24, 'declared': 23, 'stood': 23, 'cried': 22, 'had': 21, '’m': 21, 'continued': 20, 'pointed': 20, 'are': 18, 'get': 17, 'answered': 17, 'were': 16, 'been': 15, 'do': 15, 'leaned': 15, 'paused': 14, 'stepped': 14, 'began': 14, 'sat': 14, 'raised': 14, 'explained': 14, 'think': 14, 'got': 14, 'smiled': 14, 'agreed': 12, 'protested': 12, 'made': 12, 'held': 12, 'picked': 11, 'heard': 11, '…': 11, 'offered': 11, 'rolled': 11, 'go': 11, 'nodded': 10, 'see': 10, 'going': 10, 'took': 10, 'wondered': 10, 'found': 9, 'help': 9, 'fell': 9, 'told': 9, 'playing': 9, 'realized': 9, 'caught': 9, 'let': 9, 'want': 8, 'leapt': 8, 'tried': 8, 'stopped': 8, 'decided': 8, 'Let': 8, 'am': 8, 'came': 7, 'pulled': 7, 'gone': 7, 'added': 7, 'rose': 7, 'dropped': 7, 'called': 7, 'interrupted': 7, 'acknowledged': 7, 'does': 7, 'moved': 7, 'corrected': 7, 'commanded': 7, 'believe': 7, 'Is': 7, 'ran': 7, 'find': 7, 'cast': 6, 'felt': 6, 'finished': 6, 'exclaimed': 6, 'insisted': 6, 'informed': 6, 'has': 6, 'set': 6, 'understood': 6, 'remembered': 6, 'shook': 6, 'spoke': 6, 'Wait': 6, 'waved': 6, 'suggested': 6, 'demanded': 6, 'guess': 6, 'laughed': 6, 'appeared': 5, 'intoned': 5, 'howled': 5, 'cut': 5, 'supposed': 5, 'shouted': 5, 'countered': 5, 'played': 5, 'come': 5, 'mumbled': 5, 'started': 5, 'hear': 5, 'exulted': 5, 'whined': 5, 'play': 5, 'See': 5, 'opened': 5, 'look': 5, 'make': 5, 'handed': 5, 'affirmed': 5, 'put': 5, 'gon': 5, 'seduce': 5, 'returned': 5, 'led': 5, 'grabbed': 5, 'Thank': 5, 'brought': 4, 'examined': 4, 'mused': 4, 'joined': 4, 'burst': 4, 'bowed': 4, 'drew': 4, 'blinked': 4, 'threw': 4, 'Was': 4, 'rested': 4, 'saw': 4, 'sighed': 4, 'muttered': 4, 'knew': 4, 'understand': 4, 'greeted': 4, 'need': 4, 'considered': 4, 'approached': 4, 'seen': 4, 'repeated': 4, 'apologized': 4, 'read': 4, 'announced': 4, 'tell': 4, 'gave': 4, 'Shut': 4, 'challenged': 4, 'stab': 4, 'Go': 4, 'glared': 4, 'snapped': 4, 'take': 4, 'observed': 4, 'reassured': 4, 'patted': 4, 'erupted': 4, 'became': 4, 'shrieked': 4, 'remember': 4, 'say': 4, 'suppose': 4, 'reached': 4, 'like': 4, 'Keep': 4, 'killed': 4, 'accused': 4, 'wish': 4, 'screamed': 4, 'use': 4, 'seized': 3, 'decorated': 3, 'lay': 3, 'noticed': 3, 'strode': 3, 'huddled': 3, 'ends': 3, 'wrapped': 3, 'retorted': 3, 'giving': 3, 'blame': 3, 'confirmed': 3, 'moaned': 3, 'left': 3, 'inquired': 3, 'thinking': 3, 'responded': 3, 'stuck': 3, 'typed': 3, 'popped': 3, 'stammered': 3, 'looking': 3, 'taken': 3, 'hate': 3, 'doing': 3, 'murmured': 3, 'ordered': 3, 'rubbed': 3, 'conceded': 3, 'assured': 3, 'waiting': 3, 'echoed': 3, 'argued': 3, 'fumed': 3, 'gazed': 3, 'cringed': 3, 'prompted': 3, 'tucked': 3, 'flanked': 3, 'seemed': 3, 'reminded': 3, 'removed': 3, 'snatched': 3, 'says': 3, 'addressed': 3, 'glanced': 3, 'waited': 3, 'fired': 3, 'sprang': 3, 'touched': 3, 'resurrect': 3, 'jerked': 3, 'forced': 3, 'Tell': 3, 'followed': 3, 'swung': 3, 'stormed': 3, 'Come': 3, 'watched': 3, 'went': 3, 'happened': 3, 'frowned': 3, 'amended': 3, 'trapped': 3, 'headed': 3, 'belched': 3, 'managed': 3, 'attacked': 3, 'charged': 3, 'slipped': 3, 'backstab': 3, 'hand': 3, 'appears': 2, 'Return': 2, 'stalked': 2, 'broken': 2, 'engaged': 2, 'kicked': 2, 'fall': 2, 'accepted': 2, 'flowed': 2, 'avowed': 2, 'skewered': 2, 'flipped': 2, 'brings': 2, 'objected': 2, 'figure': 2, 'glowered': 2, 'rushed': 2, 'died': 2, 'growled': 2, 'Were': 2, 'gaming': 2, 'die': 2, 'try': 2, 'run': 2, 'escaped': 2, 'join': 2, 'used': 2, 'joining': 2, 'surprised': 2, 'hung': 2, 'spat': 2, 'cared': 2, 'being': 2, 'entered': 2, 'proclaimed': 2, 'exchanged': 2, 'notice': 2, 'smirked': 2, 'stuttered': 2, 'gets': 2, 'seem': 2, 'worked': 2, 'attempted': 2, 'gaped': 2, 'beat': 2, 'step': 2, 'spent': 2, 'stifled': 2, 'cheered': 2, 'met': 2, 'entreated': 2, 'clarified': 2, 'present': 2, 'light': 2, 'wandered': 2, 'faded': 2, 'worry': 2, 'stabbed': 2, 'saying': 2, 'complained': 2, 'trying': 2, 'Got': 2, 'recovered': 2, 'talking': 2, 'did': 2, 'leads': 2, 'droned': 2, 'calls': 2, 'eyed': 2, 'oozed': 2, 'winds': 2, 'fallen': 2, 'guarded': 2, 'surrounded': 2, 'sneak': 2, 'opined': 2, 'settled': 2, 'wait': 2, 'poured': 2, 'sounded': 2, 'produced': 2, 'smacked': 2, 'destroyed': 2, 'Move': 2, 'slew': 2, 'whispered': 2, 'require': 2, 'spoken': 2, 'known': 2, 'focused': 2, 'lowered': 2, 'hurled': 2, 'pushed': 2, 'bellowed': 2, 'necromancing': 2, 'ended': 2, 'tripped': 2, 'faltered': 2, 'knows': 2, 'sidled': 2, 'walked': 2, 'allow': 2, 'lamented': 2, 'Ransomed': 2, 'disagreed': 2, 'Save': 2, 'dismissed': 2, 'scoffed': 2, 'approved': 2, 'gestured': 2, 'kept': 2, 'demurred': 2, 'getting': 2, 'keep': 2, 'trust': 2, 'laid': 2, 'spun': 2, 'paying': 2, 'save': 2, 'working': 2, 'tossed': 2, 'sent': 2, 'guessed': 2, 'blurted': 2, 'aimed': 2, 'begged': 2, 'invited': 2, 'pressed': 2, 'folded': 2, 'completed': 2, 'grinned': 2, 'brightened': 2, 'hit': 2, 'whipped': 2, 'slapped': 2, 'Prepare': 2, 'taunted': 2, 'closed': 2, 'expecting': 2, 'mind': 2, 'bless': 2, 'stand': 2, 'widened': 2, 'clapped': 2, 'seems': 2, 'chose': 2, 'threatened': 2, 'instructed': 2, 'donned': 2, 'spotted': 2, 'emerged': 2, 'freed': 2, 'mean': 2, 'beaten': 2, 'wasted': 2, 'learned': 2, 'bathed': 2, 'Adapted': 1, 'Published': 1, 'inherits': 1, 'marked': 1, 'lumbered': 1, 'vanished': 1, 'creaked': 1, 'expanded': 1, 'scattered': 1, 'shone': 1, 'Stay': 1, 'dispatched': 1, 'end': 1, 'separated': 1, 'crossed': 1, 'leveled': 1, 'lived': 1, 'dying': 1, 'emphasized': 1, 'mention': 1, 'fit': 1, 'trumps': 1, 'expect': 1, 'Argue': 1, 'separate': 1, 'scowled': 1, 'injected': 1, 'comes': 1, 'Looks': 1, 'commit': 1, 'figured': 1, 'overrode': 1, 'emitted': 1, 'adding': 1, 'bushwhacked': 1, 'Take': 1, 'filled': 1, 'remarked': 1, 'explodes': 1, 'given': 1, 'mentioned': 1, 'gamed': 1, 'froze': 1, 'imagine': 1, 'sauntered': 1, 'dated': 1, 'remained': 1, 'drawn': 1, 'arrived': 1, 'noted': 1, 'leaving': 1, 'slow': 1, 'drank': 1, 'owned': 1, 'care': 1, 'liked': 1, 'marched': 1, 'queried': 1, 'tempted': 1, 'belonged': 1, 'bragged': 1, 'starting': 1, 'mimicked': 1, 'Has': 1, 'resisted': 1, 'Shake': 1, 'fights': 1, 'makes': 1, 'beginning': 1, 'dies': 1, 'Remember': 1, 'ambushed': 1, 'cool': 1, 'fought': 1, 'shoot': 1, 'break': 1, 'call': 1, 'celebrated': 1, 'promised': 1, 'assume': 1, 'based': 1, 'asking': 1, 'breaking': 1, 'indicated': 1, 'travelled': 1, 'talked': 1, 'sang': 1, 'Stab': 1, 'Remove': 1, 'Decapitate': 1, 'Begins': 1, 'begin': 1, 'grows': 1, 'discovered': 1, 'Find': 1, 'Bring': 1, 'studied': 1, 'tugged': 1, 'hawked': 1, 'sucks': 1, 'cleared': 1, 'realize': 1, 'dusted': 1, 'obliged': 1, '“': 1, 'defended': 1, 'warned': 1, 'forgetting': 1, 'begs': 1, 'Listen': 1, 'babbled': 1, 'pee': 1, 'crowned': 1, 'locked': 1, 'steal': 1, 'wished': 1, 'tune': 1, 'represent': 1, 'watches': 1, 'introduced': 1, 'lifted': 1, 'assure': 1, 'strike': 1, 'catches': 1, 'reach': 1, 'surveyed': 1, 'stands': 1, 'ringed': 1, 'chuckled': 1, 'chopped': 1, 'worship': 1, 'brandished': 1, 'wonder': 1, 'farted': 1, 'negotiate': 1, 'pacify': 1, 'intervened': 1, 'collapsed': 1, 'whacked': 1, 'shaking': 1, 'hanging': 1, 'add': 1, 'checked': 1, 'wheeled': 1, 'executed': 1, 'fluttered': 1, 'pulls': 1, 'surround': 1, 'Hold': 1, 'fished': 1, 'uses': 1, 'Sing': 1, 'rejoiced': 1, 'Give': 1, 'cause': 1, 'tumble': 1, 'sped': 1, 'barked': 1, 'squatted': 1, 'stumbled': 1, 'scanned': 1, 'delivered': 1, 'served': 1, 'Must': 1, 'must': 1, 'giggled': 1, 'crooned': 1, 'draw': 1, 'mute': 1, 'concurred': 1, 'abandoned': 1, 'fixing': 1, 'belong': 1, 'serve': 1, 'billowed': 1, 'upended': 1, 'scuffled': 1, 'struggled': 1, 'control': 1, 'Are': 1, 'kno': 1, 'Do': 1, 'Kill': 1, 'Look': 1, 'Show': 1, 'escape': 1, 'sounds': 1, 'drifted': 1, 'descend': 1, 'teased': 1, 'paced': 1, 'mete': 1, 'evaded': 1, 'supported': 1, 'empathized': 1, 'suck': 1, 'recited': 1, 'abandon': 1, 'strummed': 1, 'lose': 1, 'remind': 1, 'fled': 1, 'wore': 1, 'stole': 1, 'gesturing': 1, 'yawned': 1, 'pondered': 1, 'clasped': 1, 'form': 1, 'coming': 1, 'obtain': 1, 'fear': 1, 'interjected': 1, 'gloated': 1, 'lost': 1, 'forgotten': 1, 'having': 1, 'trotted': 1, 'quoted': 1, 'climbed': 1, 'thanked': 1, 'wanted': 1, 'thanking': 1, 'admitted': 1, 'goes': 1, 'ticked': 1, 'timed': 1, 'backed': 1, 'surprise': 1, 'dismiss': 1, 'spluttered': 1, 'refused': 1, 'standing': 1, 'raced': 1, 'park': 1, 'erased': 1, 'sketched': 1, 'filling': 1, 'Regenerates': 1, 'breathes': 1, 'switched': 1, 'launched': 1, 'split': 1, 'chase': 1, 'stacked': 1, 'sensed': 1, 'connecting': 1, 'deliver': 1, 'relaxed': 1, 'deal': 1, 'bring': 1, 'jumped': 1, 'allowed': 1, 'awoke': 1, 'rummaging': 1, 'waste': 1, 'swatted': 1, 'punished': 1, 'scrutinized': 1, 'pleaded': 1, 'fool': 1, 'remembers': 1, 'kill': 1, 'Forgive': 1, 'live': 1, 'trailed': 1, 'darkened': 1, 'changed': 1, 'occurred': 1, 'chimed': 1, 'worried': 1, 'begun': 1, 'choose': 1, 'consider': 1, 'whirled': 1, 'smite': 1, 'punched': 1, 'manage': 1, 'twitched': 1, 'move': 1, 'begins': 1, 'roll': 1, 'pinched': 1, 'won': 1, 'means': 1, 'shut': 1, 'tempt': 1, 'Kiss': 1, 'slumped': 1, 'resolved': 1, 'peeked': 1, 'punctuated': 1, 'burning': 1, 'cradled': 1, 'thank': 1, 'groaned': 1, 'explain': 1, 'regain': 1, 'Assuming': 1, 'falls': 1, 'posted': 1, 'sporting': 1, 'glowed': 1, 'concentrate': 1, 'hollered': 1, 'distract': 1, 'done': 1, 'roared': 1, 'Pointing': 1, 'suggest': 1, 'blast': 1, 'Hide': 1, 'dove': 1, 'flew': 1, 'question': 1, 'give': 1, 'defeat': 1, 'emptied': 1, 'feel': 1, 'follow': 1, 'borrow': 1, 'Stop': 1, 'tiptoed': 1, 'holding': 1, 'winced': 1, 'recognize': 1, 'wearing': 1, 'Shove': 1, 'soothed': 1, 'charm': 1, 'shrugged': 1, 'named': 1, 'exited': 1, 'ruminated': 1, 'expected': 1, 'recognized': 1, 'yelled': 1, 'Pick': 1, 'likes': 1, 'sputtered': 1, 'Watch': 1, 'circled': 1, 'takes': 1, 'collided': 1, 'perched': 1, 'reassembled': 1, 'backstabbed': 1, 'cleaved': 1, 'falling': 1, 'picking': 1, 'promise': 1, 'placed': 1, 'activated': 1, 'licked': 1, 'lunged': 1, 'plucked': 1, 'unloaded': 1, 'failed': 1, 'Destroy': 1, 'achieved': 1, 'commended': 1, 'thrust': 1, 'missed': 1, 'exploded': 1, 'halted': 1, 'explode': 1, 'chided': 1, 'become': 1, 'creating': 1, 'matter': 1, 'Wonder': 1, 'endured': 1, 'forgive': 1, 'obtained': 1, 'corrupted': 1, 'meandered': 1, 'shame': 1, 'Lose': 1, 'withdrawn': 1, 'knocked': 1, 'ducked': 1, 'ripped': 1, 'munched': 1, 'decreed': 1, 'arrive': 1, 'hid': 1, 'Raise': 1, 'Be': 1, 'beckoned': 1, 'beg': 1, 'sounding': 1, 'recoiled': 1, 'rekindled': 1, 'drives': 1, 'finds': 1, 'rule': 1, 'resurrected': 1, 'winked': 1, 'silenced': 1, 'writhed': 1, 'showed': 1, 'sank': 1, 'grant': 1, 'admonished': 1, 'Think': 1, 'Wish': 1, 'advancing': 1, 'slammed': 1, 'gathered': 1, 'ruined': 1, 'slid': 1, 'happens': 1, 'broke': 1, 'knelt': 1, 'reappeared': 1, 'summoned': 1, 'creates': 1, 'gain': 1, 'exhorted': 1, 'dressed': 1, 'burned': 1, 'replaced': 1, 'disregarded': 1, 'helped': 1, 'dub': 1, 'ascended': 1, 'lit': 1, 'beamed': 1, 'ruffled': 1, 'Recognize': 1, 'dodged': 1, 'tapped': 1, 'bothered': 1, 'passed': 1, 'filtered': 1, 'sleep': 1, 'spellbound': 1, 'intercepted': 1, 'check': 1, 'plowed': 1, 'hesitated': 1, 'bother': 1, '‘': 1, 'hoped': 1, 'talk': 1, 'tipped': 1, 'ignored': 1, 'Starts': 1, 'saved': 1, 'steepled': 1, 'tumbled': 1, 'Sit': 1, 'Speak': 1, 'reported': 1, 'Stolen': 1, 'risk': 1, 'Hope': 1, 'cherish': 1, 'established': 1, 'exposed': 1, 'located': 1, 'bothering': 1, 'speaks': 1, 'love': 1, 'Rising': 1})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract all the personal names from Pride & Prejudice and count their occurrences. \n",
    "# Expected output is a list in the following form: [('elizabeth', 622), ('darcy', 312), ('jane', 286), ('bennet', 266) ...].\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "test = \"The birds and the beasts were there\"\n",
    "processed_test = nlp(test)\n",
    "\n",
    "\n",
    "\n",
    "def extract_finite_verb(doc):\n",
    "    \n",
    "    characters_verb = Counter()\n",
    "    \n",
    "    i = 1\n",
    "    for token in processed_text:\n",
    "        #print(token.pos_)\n",
    "        i += 1\n",
    "        if token.dep_ == 'ROOT' and token.head.pos_ == 'VERB' :\n",
    "            if token.dep_ == \"prt\" and token.head.pos_ == \"VERB\" :\n",
    "                verb = token.head.orth_\n",
    "                particle = token.orth_\n",
    "                characters_verb[verb + '-' + particle] += 1\n",
    "            characters_verb[token.text] += 1\n",
    "            #if (token.pos_ == 'CONJ') :\n",
    "            \n",
    "            #print(i)\n",
    "            \n",
    "    return characters_verb\n",
    "\n",
    "\n",
    "\n",
    "def extract_finite_noun(doc):\n",
    "    \n",
    "    characters_noun = Counter()\n",
    "    \n",
    "    for token in processed_text:\n",
    "        #print(token.pos_)\n",
    "        if token.dep_ == 'ROOT' and token.pos_ == 'NOUN' :\n",
    "            characters_noun[token.text] += 1\n",
    "            #print([child for child in token.children], token.text)\n",
    "            if (token.pos_ == 'CONJ') :\n",
    "                print('There is a conjunction')\n",
    "            #print(token.text)\n",
    "    return characters_noun\n",
    "\n",
    "def extract_finite_adj(doc):\n",
    "    \n",
    "    characters_adj = Counter()\n",
    "    \n",
    "    for token in processed_text:\n",
    "        #print(token.pos_)\n",
    "        if token.dep_ == 'ROOT' and token.pos_ == 'ADJ' :\n",
    "            characters_adj[token.lemma_] += 1\n",
    "            \n",
    "    return characters_adj\n",
    "\n",
    "\n",
    "#print(processed_text.sents[sent_index[6]])\n",
    "\n",
    "    \n",
    "print(extract_finite_verb(processed_text))\n",
    "#print(\"\\n\")\n",
    "#print(extract_finite_noun(processed_text))\n",
    "#print(\"\\n\")\n",
    "#print(extract_finite_adj(processed_text))\n",
    "#print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stepped-up\n",
      "Holding-forth\n",
      "point-out\n",
      "put-up\n",
      "lined-up\n",
      "looked-down\n",
      "looked-down\n",
      "threw-up\n",
      "cut-off\n",
      "drowned-out\n",
      "leaned-in\n",
      "cut-off\n",
      "cutting-off\n",
      "figure-out\n",
      "Argue-on\n",
      "cut-off\n",
      "shut-down\n",
      "strike-out\n",
      "figured-out\n",
      "work-out\n",
      "continued-on\n",
      "picked-up\n",
      "held-out\n",
      "hung-up\n",
      "pissed-off\n",
      "call-around\n",
      "sauntered-up\n",
      "seen-in\n",
      "putting-up\n",
      "broken-up\n",
      "hung-out\n",
      "hang-out\n",
      "slow-down\n",
      "slow-down\n",
      "slow-down\n",
      "leapt-up\n",
      "look-over\n",
      "bounded-off\n",
      "stared-up\n",
      "looked-up\n",
      "popped-out\n",
      "stood-up\n",
      "looked-up\n",
      "sat-down\n",
      "pointed-out\n",
      "figure-out\n",
      "held-out\n",
      "counting-off\n",
      "worked-up\n",
      "holding-up\n",
      "gave-up\n",
      "broken-up\n",
      "look-up\n",
      "Shut-up\n",
      "looking-up\n",
      "Shut-up\n",
      "looking-up\n",
      "looked-up\n",
      "Shut-UP\n",
      "cut-in\n",
      "setting-down\n",
      "picking-up\n",
      "cool-down\n",
      "came-out\n",
      "picked-up\n",
      "picking-up\n",
      "break-up\n",
      "cut-off\n",
      "pointed-out\n",
      "pointed-out\n",
      "held-out\n",
      "picked-up\n",
      "turned-around\n",
      "picked-up\n",
      "drown-out\n",
      "joined-in\n",
      "joined-in\n",
      "ran-off\n",
      "chatting-up\n",
      "leaned-in\n",
      "threw-up\n",
      "get-on\n",
      "snatched-up\n",
      "rushed-off\n",
      "catch-up\n",
      "tore-off\n",
      "strike-out\n",
      "glanced-around\n",
      "picking-up\n",
      "go-off\n",
      "stood-up\n",
      "dusted-off\n",
      "give-up\n",
      "sped-off\n",
      "turned-around\n",
      "stared-down\n",
      "sat-down\n",
      "billowed-up\n",
      "snatched-up\n",
      "come-up\n",
      "swung-down\n",
      "picked-up\n",
      "leapt-up\n",
      "work-out\n",
      "leapt-up\n",
      "joined-in\n",
      "pointed-out\n",
      "pointed-out\n",
      "held-up\n",
      "pointed-out\n",
      "turned-up\n",
      "drifted-in\n",
      "floating-out\n",
      "picked-up\n",
      "ran-off\n",
      "mete-out\n",
      "find-out\n",
      "finding-out\n",
      "burned-down\n",
      "sidled-over\n",
      "cut-off\n",
      "stretching-out\n",
      "looked-up\n",
      "flipping-over\n",
      "caught-on\n",
      "turning-over\n",
      "held-out\n",
      "snapped-up\n",
      "rose-up\n",
      "pointed-out\n",
      "looked-up\n",
      "packed-up\n",
      "pulled-out\n",
      "trotted-up\n",
      "playing-along\n",
      "found-out\n",
      "sat-down\n",
      "run-off\n",
      "let-out\n",
      "backed-up\n",
      "stared-down\n",
      "picked-up\n",
      "drew-out\n",
      "gave-in\n",
      "continued-on\n",
      "turned-on\n",
      "whirl-around\n",
      "picked-up\n",
      "stared-down\n",
      "droned-on\n",
      "looked-up\n",
      "filling-out\n",
      "laid-out\n",
      "Shut-up\n",
      "held-out\n",
      "called-out\n",
      "Keep-up\n",
      "continued-on\n",
      "racing-out\n",
      "chase-down\n",
      "dashed-off\n",
      "set-down\n",
      "give-up\n",
      "looked-up\n",
      "bring-in\n",
      "bring-in\n",
      "setting-out\n",
      "jumped-up\n",
      "picking-up\n",
      "left-off\n",
      "caught-up\n",
      "burn-out\n",
      "swatted-down\n",
      "pointed-out\n",
      "Pushing-down\n",
      "calm-down\n",
      "Shut-up\n",
      "trailed-off\n",
      "held-up\n",
      "cried-out\n",
      "pointed-out\n",
      "looked-on\n",
      "bring-down\n",
      "bringing-down\n",
      "move-on\n",
      "break-up\n",
      "picked-up\n",
      "looking-down\n",
      "snap-out\n",
      "held-out\n",
      "snapped-up\n",
      "shut-up\n",
      "worked-out\n",
      "looked-on\n",
      "looked-down\n",
      "go-in\n",
      "stepped-out\n",
      "picked-up\n",
      "slammed-down\n",
      "picked-up\n",
      "shook-off\n",
      "Keep-down\n",
      "looking-up\n",
      "whipped-out\n",
      "ran-in\n",
      "slapped-down\n",
      "pressed-in\n",
      "rise-up\n",
      "carried-off\n",
      "looking-up\n",
      "came-up\n",
      "carried-off\n",
      "stepped-out\n",
      "looking-up\n",
      "slapped-down\n",
      "stand-up\n",
      "held-up\n",
      "pointed-out\n",
      "gave-in\n",
      "cut-off\n",
      "laying-out\n",
      "looked-down\n",
      "Move-out\n",
      "handed-off\n",
      "stepped-up\n",
      "pulled-up\n",
      "hanging-down\n",
      "pulled-down\n",
      "looked-on\n",
      "working-through\n",
      "Shove-off\n",
      "held-out\n",
      "holding-up\n",
      "handing-off\n",
      "cut-off\n",
      "glancing-around\n",
      "bricked-up\n",
      "lined-up\n",
      "looked-down\n",
      "sputtered-out\n",
      "Watch-out\n",
      "sprang-up\n",
      "looked-up\n",
      "stared-down\n",
      "looked-up\n",
      "picked-up\n",
      "pointed-out\n",
      "bobbed-up\n",
      "pulled-down\n",
      "ran-up\n",
      "picking-up\n",
      "snuffing-out\n",
      "picked-up\n",
      "pushed-forth\n",
      "looked-around\n",
      "shutting-up\n",
      "pointed-out\n",
      "pointed-out\n",
      "looked-up\n",
      "lit-up\n",
      "hand-over\n",
      "hand-over\n",
      "hand-over\n",
      "stalked-off\n",
      "sticks-out\n",
      "knocking-down\n",
      "ducked-down\n",
      "held-up\n",
      "strode-up\n",
      "ripped-off\n",
      "tossed-down\n",
      "find-out\n",
      "holding-out\n",
      "slipped-out\n",
      "strode-in\n",
      "pointed-out\n",
      "finds-out\n",
      "pulled-out\n",
      "winked-out\n",
      "pointed-out\n",
      "slammed-down\n",
      "leaning-over\n",
      "brought-in\n",
      "caught-up\n",
      "stepping-out\n",
      "looked-up\n",
      "moved-on\n",
      "lit-up\n",
      "leaping-up\n",
      "heading-out\n",
      "turning-around\n",
      "sat-down\n",
      "gather-up\n",
      "cleaning-up\n",
      "padding-down\n",
      "stepped-up\n",
      "whipping-around\n",
      "settled-in\n",
      "holding-up\n",
      "check-out\n",
      "lined-up\n",
      "plowed-down\n",
      "stood-up\n",
      "holding-up\n",
      "starting-up\n",
      "stop-by\n",
      "reached-out\n",
      "grow-up\n",
      "held-out\n",
      "leaned-down\n",
      "pick-up\n",
      "tipped-off\n",
      "flipping-around\n",
      "left-off\n",
      "sidled-up\n",
      "waving-off\n",
      "Keep-up\n",
      "turned-up\n"
     ]
    }
   ],
   "source": [
    "def phrasal_verb_recognizer() :\n",
    "        for token in processed_text :\n",
    "            if token.dep_ == \"prt\" and token.head.pos_ == \"VERB\":\n",
    "                verb = token.head.orth_\n",
    "                particle = token.orth_\n",
    "                print(verb + '-' + particle)\n",
    "                \n",
    "#print(phrasal_verb_recognizer(processed_text))\n",
    "phrasal_verb_recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot characters personal names as a time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib Jupyter HACK\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot characters' mentions as a time series relative to the position of the actor's occurrence in a book.\n",
    "\n",
    "def get_character_offsets(doc):\n",
    "    \"\"\"\n",
    "    For every character in a `doc` collect all the occurences offsets and store them into a list. \n",
    "    The function returns a dictionary that has actor lemma as a key and list of occurences as a value for every character.\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :return: dict object in form\n",
    "        {'elizabeth': [123, 543, 4534], 'darcy': [205, 2111]}\n",
    "    \"\"\"\n",
    "    \n",
    "    character_offsets = defaultdict(list)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            character_offsets[ent.lemma_].append(ent.start)\n",
    "            \n",
    "    return dict(character_offsets)\n",
    "\n",
    "character_occurences = get_character_offsets(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'penzias'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fd6caa223a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#plot_character_timeseries(character_occurences, ['darcy', 'bingley'], normalization_constant=len(processed_text))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mplot_character_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_occurences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'penzias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'moon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-fd6caa223a25>\u001b[0m in \u001b[0;36mplot_character_timeseries\u001b[0;34m(character_offsets, character_labels, normalization_constant)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mnormalization_constant\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcharacter_offsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacter_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcharacter_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcharacter_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fivethirtyeight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-fd6caa223a25>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mnormalization_constant\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcharacter_offsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacter_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcharacter_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcharacter_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fivethirtyeight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'penzias'"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import hist\n",
    "from cycler import cycler\n",
    "\n",
    "NUM_BINS = 10\n",
    "\n",
    "def normalize(occurencies, normalization_constant):\n",
    "    return [o / float(len(processed_text)) for o in occurencies]\n",
    "\n",
    "def plot_character_timeseries(character_offsets, character_labels, normalization_constant=None):\n",
    "    \"\"\"\n",
    "    Plot characters' personal names specified in `character_labels` list as time series.\n",
    "    \n",
    "    :param character_offsets: dict object in form {'elizabeth': [123, 543, 4534], 'darcy': [205, 2111]}\n",
    "    :param character_labels: list of strings that should match some of the keys in `character_offsets`\n",
    "    :param normalization_constant: int\n",
    "    \"\"\"\n",
    "    x = [character_offsets[character_label] for character_label in character_labels] \n",
    "        \n",
    "    with plt.style.context('fivethirtyeight'):\n",
    "        plt.figure()\n",
    "        n, bins, patches = plt.hist(x, NUM_BINS, label=character_labels)\n",
    "        plt.clf()\n",
    "        \n",
    "        ax = plt.subplot(111)\n",
    "        for i, a in enumerate(n):\n",
    "            ax.plot([float(x) / (NUM_BINS - 1) for x in range(len(a))], a, label=character_labels[i])\n",
    "            \n",
    "        matplotlib.rcParams['axes.prop_cycle'] = cycler(color=['r','k','c','b','y','m','g','#54a1FF'])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "#plot_character_timeseries(character_occurences, ['darcy', 'bingley'], normalization_constant=len(processed_text))\n",
    "plot_character_timeseries(character_occurences, ['penzias', 'moon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy parse tree in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Find words (adjectives) that describe Mr. Darcy.\n",
    "\n",
    "def get_character_adjectives(doc, character_lemma):\n",
    "    \"\"\"\n",
    "    Find all the adjectives related to `character_lemma` in `doc`\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :param character_lemma: string object\n",
    "    :return: list of adjectives related to `character_lemma`\n",
    "    \"\"\"\n",
    "    \n",
    "    adjectives = []\n",
    "    for ent in processed_text.ents:\n",
    "        if ent.lemma_ == character_lemma:\n",
    "            for token in ent.subtree:\n",
    "                if token.pos_ == 'ADJ': # Replace with if token.dep_ == 'amod':\n",
    "                    #adjectives.append(token.lemma_)\n",
    "                    print('hi')\n",
    "    \n",
    "    for ent in processed_text.ents:\n",
    "        if ent.lemma_ == character_lemma:\n",
    "            if ent.root.dep_ == 'nsubj':\n",
    "                for child in ent.root.head.children:\n",
    "                    if child.dep_ == 'acomp':\n",
    "                        adjectives.append(child.lemma_)\n",
    "    \n",
    "    return adjectives\n",
    "\n",
    "print(get_character_adjectives(processed_text, 'penzias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e05f32d22140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# entities and corresponding root verbs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcharacter_verb_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mVERB_LEMMA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "# Find characters that are 'talking', 'saying', 'doing' the most. Find the relationship between \n",
    "# entities and corresponding root verbs.\n",
    "\n",
    "character_verb_counter = Counter()\n",
    "VERB_LEMMA = 'count'\n",
    "\n",
    "for ent in processed_text.ents:\n",
    "    if ent.label_ == 'PERSON' and ent.root.head.lemma_ == VERB_LEMMA:\n",
    "        character_verb_counter[ent.text] += 1\n",
    "\n",
    "print(character_verb_counter.most_common(10)) \n",
    "        \n",
    "# Find all the characters that got married in the book.\n",
    "#\n",
    "# Here is an example sentence from which this information could be extracted:\n",
    "# \n",
    "# \"her mother was talking to that one person (Lady Lucas) freely,\n",
    "# openly, and of nothing else but her expectation that Jane would soon\n",
    "# be married to Mr. Bingley.\"\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-21de6662fc60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Try to find a way to remove non informative keywords.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/article.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract Keywords using noun chunks from the news article (file 'article.txt').\n",
    "# Spacy will pick some noun chunks that are not informative at all (e.g. we, what, who).\n",
    "# Try to find a way to remove non informative keywords.\n",
    "\n",
    "article = read_file('Data/article.txt')\n",
    "doc = nlp(article)\n",
    "\n",
    "keywords = Counter()\n",
    "for chunk in doc.noun_chunks:\n",
    "    if nlp.vocab[chunk.lemma_].prob < - 8: # probablity value -8 is arbitrarily selected threshold\n",
    "        keywords[chunk.lemma_] += 1\n",
    "\n",
    "keywords.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please wait a moment while I gather a list of all available modules...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated since IPython 4.0.You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseHTTPServer      atexit              io                  shlex\n",
      "Bastion             audiodev            ipykernel           shutil\n",
      "CDROM               audioop             ipython_genutils    shutil_backports\n",
      "CGIHTTPServer       autoreload          itertools           signal\n",
      "Canvas              axi                 json                simplegeneric\n",
      "ConfigParser        backports           jupyter             singledispatch\n",
      "Cookie              backports_abc       jupyter_client      singledispatch_helpers\n",
      "DLFCN               base64              jupyter_core        site\n",
      "Dialog              bdb                 keyword             sitecustomize\n",
      "DocXMLRPCServer     binascii            landscape           six\n",
      "FileDialog          binhex              lib2to3             smtpd\n",
      "FixTk               bisect              linecache           smtplib\n",
      "HTMLParser          bsddb               linuxaudiodev       sndhdr\n",
      "IN                  bz2                 locale              socket\n",
      "IPython             cPickle             logging             spwd\n",
      "MimeWriter          cProfile            lsb_release         sqlite3\n",
      "OpenSSL             cStringIO           macpath             sre\n",
      "PAM                 calendar            macurl2path         sre_compile\n",
      "Queue               certifi             mailbox             sre_constants\n",
      "ScrolledText        cgi                 mailcap             sre_parse\n",
      "SimpleDialog        cgitb               markupbase          ssl\n",
      "SimpleHTTPServer    chardet             marshal             stat\n",
      "SimpleXMLRPCServer  chunk               math                statvfs\n",
      "SocketServer        cmath               md5                 storemagic\n",
      "StringIO            cmd                 mhlib               string\n",
      "TYPES               code                mimetools           stringold\n",
      "Tix                 codecs              mimetypes           stringprep\n",
      "Tkconstants         codeop              mimify              strop\n",
      "Tkdnd               collections         mmap                struct\n",
      "Tkinter             colorsys            modulefinder        subprocess\n",
      "UserDict            commands            multifile           sunau\n",
      "UserList            compileall          multiprocessing     sunaudio\n",
      "UserString          compiler            mutex               svg_regex\n",
      "_LWPCookieJar       configobj           netrc               svg_transform\n",
      "_MozillaCookieJar   contextlib          new                 symbol\n",
      "__builtin__         cookielib           nis                 sympyprinting\n",
      "__future__          copy                nntplib             symtable\n",
      "_abcoll             copy_reg            ntpath              sys\n",
      "_ast                crypt               nturl2path          sysconfig\n",
      "_bisect             csv                 numbers             syslog\n",
      "_bsddb              ctypes              opcode              tabnanny\n",
      "_codecs             curses              operator            tarfile\n",
      "_codecs_cn          cythonmagic         optparse            telnetlib\n",
      "_codecs_hk          datetime            os                  tempfile\n",
      "_codecs_iso2022     dateutil            os2emxpath          termios\n",
      "_codecs_jp          dbhash              ossaudiodev         test\n",
      "_codecs_kr          dbm                 packaging           tests\n",
      "_codecs_tw          deb822              parser              textwrap\n",
      "_collections        debconf             pathlib2            this\n",
      "_csv                debian              pdb                 thread\n",
      "_ctypes             debian_bundle       pexpect             threading\n",
      "_ctypes_test        decimal             pickle              time\n",
      "_curses             decorator           pickleshare         timeit\n",
      "_curses_panel       difflib             pickletools         tkColorChooser\n",
      "_elementtree        dircache            pip                 tkCommonDialog\n",
      "_functools          dis                 pipes               tkFileDialog\n",
      "_hashlib            distutils           pkg_resources       tkFont\n",
      "_heapq              doctest             pkgutil             tkMessageBox\n",
      "_hotshot            dumbdbm             platform            tkSimpleDialog\n",
      "_io                 dummy_thread        plistlib            toaiff\n",
      "_json               dummy_threading     popen2              token\n",
      "_locale             easy_install        poplib              tokenize\n",
      "_lsprof             email               posix               tornado\n",
      "_md5                encodings           posixfile           trace\n",
      "_multibytecodec     enum                posixpath           traceback\n",
      "_multiprocessing    errno               pprint              traitlets\n",
      "_osx_support        exceptions          profile             ttk\n",
      "_pyio               fcntl               prompt_toolkit      tty\n",
      "_random             filecmp             pstats              turtle\n",
      "_scandir            fileinput           pty                 twisted\n",
      "_sha                fnmatch             ptyprocess          types\n",
      "_sha256             formatter           pwd                 unicodedata\n",
      "_sha512             fpectl              py_compile          unittest\n",
      "_socket             fpformat            pyclbr              urllib\n",
      "_sqlite3            fractions           pydoc               urllib2\n",
      "_sre                ftplib              pydoc_data          urllib3\n",
      "_ssl                functools           pyexpat             urlparse\n",
      "_strptime           future_builtins     pygments            user\n",
      "_struct             gc                  pyparsing           uu\n",
      "_symtable           gdbm                quopri              uuid\n",
      "_sysconfigdata      genericpath         random              validate\n",
      "_sysconfigdata_d    getopt              re                  warnings\n",
      "_sysconfigdata_nd   getpass             readline            wave\n",
      "_testcapi           gettext             repr                wcwidth\n",
      "_threading_local    glob                requests            weakref\n",
      "_warnings           grp                 resource            webbrowser\n",
      "_weakref            gyp                 rexec               wheel\n",
      "_weakrefset         gzip                rfc822              whichdb\n",
      "abc                 hashlib             rlcompleter         wsgiref\n",
      "aifc                heapq               rmagic              xapian\n",
      "antigravity         hmac                robotparser         xdrlib\n",
      "anydbm              hotshot             runpy               xml\n",
      "appdirs             htmlentitydefs      scandir             xmllib\n",
      "apt                 htmllib             sched               xmlrpclib\n",
      "apt_inst            httplib             scour               xxsubtype\n",
      "apt_pkg             ihooks              select              yocto_css\n",
      "aptsources          imaplib             serial              zipfile\n",
      "argparse            imghdr              sets                zipimport\n",
      "array               imp                 setuptools          zlib\n",
      "ast                 importlib           sgmllib             zmq\n",
      "asynchat            imputil             sha                 zope\n",
      "asyncore            inspect             shelve              \n",
      "\n",
      "Enter any module name to get more help.  Or, type \"modules spam\" to search\n",
      "for modules whose descriptions contain the word \"spam\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
